{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import datetime\n",
    "import boto3\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import plotly.express as px\n",
    "import io\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(): \n",
    "    s3 = boto3.client('s3') # comment out when on local\n",
    "    obj = s3.get_object(Bucket = 'lawyer-predict', Key = 'df.csv')\n",
    "    data_fnc = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    s3_bucket_stuff = boto3.resource('s3')\n",
    "    bucket = s3_bucket_stuff.Bucket('lawyer-predict')    \n",
    "    for file in bucket.objects.all():    \n",
    "        file_date = file.last_modified.replace(tzinfo=None)\n",
    "    \n",
    "    return data_fnc, file_date\n",
    "\n",
    "data_orig, date_modified = load_data()\n",
    "\n",
    "data = data_orig.copy()\n",
    "\n",
    "#categorize decisions as acceptance as 1 , waitlisted as 2 or denied as 0\n",
    "data.loc[data.decision.isin(['Accepted', 'Accepted Attending', 'Accepted Deferred', 'Accepted Deferred Attending', 'Accepted Deferred Withdrawn', 'Accepted Withdrawn']), 'decision_numeric'] = 1\n",
    "\n",
    "data.loc[data.decision.isin(['Rejected', 'Rejected Attending', 'Rejected Deferred', 'Rejected Withdrawn']), 'decision_numeric'] = 0\n",
    "\n",
    "data.loc[data.decision.isin(['WL Accepted', 'WL Accepted Attending', 'WL Accepted Deferred', 'WL Accepted Deferred Attending', 'WL Accepted Withdrawn', 'WL Rejected', 'WL Rejected Deferred', 'WL Rejected Withdrawn', 'WL Withdrawn', 'Waitlisted', 'Waitlisted Attending', 'Waitlisted Deferred', 'Waitlisted Withdrawn']), 'decision_numeric'] = 2\n",
    "\n",
    "data.loc[data.decision.isin(['Intend to Apply', 'Intend to Apply Attending', 'Intend to Apply Deferred Withdrawn', 'Intend to Apply Withdrawn', 'Pending', 'Pending Attending', 'Pending Deferred', 'Pending Deferred Withdrawn', 'Pending Withdrawn']), 'decision_numeric'] = np.nan\n",
    "\n",
    "data = data.loc[~data.decision_numeric.isna()]\n",
    "#drop where job experience not given\n",
    "data = data.loc[data.work_experience != '?']\n",
    "#label encode work experience\n",
    "data.loc[data.work_experience == '0 years (KJD)', 'work_experience_encode'] = 0\n",
    "data.loc[data.work_experience == '1-4 years', 'work_experience_encode'] = 1\n",
    "data.loc[data.work_experience == '5-9 years', 'work_experience_encode'] = 2\n",
    "data.loc[data.work_experience == '10+ years', 'work_experience_encode'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build and test models based on Vandy\n",
    "\n",
    "school_name = 'Vanderbilt University'\n",
    "school_orig = data.loc[data.school == school_name][['decision_numeric', 'gpa', 'lsat', 'urm', 'work_experience_encode', 'cycleid']].dropna().reset_index()\n",
    "school_orig = school_orig.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1355, 5)\n",
      "0.6229508196721312\n",
      "1.0031850252025685\n"
     ]
    }
   ],
   "source": [
    "#baseline model\n",
    "baseline_train = school_orig.loc[school_orig.cycleid != 17]\n",
    "#baseline_train_y = baseline_train.decision_numeric.reset_index()\n",
    "baseline_train_y = baseline_train.decision_numeric\n",
    "\n",
    "baseline_train_x = baseline_train.drop('decision_numeric', axis =1)\n",
    "\n",
    "baseline_test = school_orig.loc[school_orig.cycleid == 17] \n",
    "baseline_test_y = baseline_test.decision_numeric\n",
    "baseline_test_x = baseline_test.drop('decision_numeric', axis =1)\n",
    "\n",
    "print(baseline_train_x.shape)\n",
    "\n",
    "xgb_baseline = XGBClassifier(num_classes = 3, random_state = 12)\n",
    "# preds are gpa, lsat, urm, work_experience, \n",
    "xgb_baseline.fit(baseline_train_x, baseline_train_y)\n",
    "\n",
    "f1_score_list = []\n",
    "log_loss_list = []\n",
    "\n",
    "f1_score_baseline = f1_score(baseline_test_y, xgb_baseline.predict(baseline_test_x), average = 'micro')\n",
    "log_loss_baseline = log_loss(baseline_test_y, xgb_baseline.predict_proba(baseline_test_x))\n",
    "\n",
    "f1_score_list.append(f1_score_baseline)\n",
    "log_loss_list.append(log_loss_baseline)\n",
    "\n",
    "print(f1_score_baseline)\n",
    "print(log_loss_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2261, 5)\n",
      "0.639344262295082\n",
      "1.0319778619669988\n"
     ]
    }
   ],
   "source": [
    "#duplicate rows for training\n",
    "cycle16_indicies = baseline_train_x.loc[baseline_train_x.cycleid==16].index\n",
    "df_cycle16_train = baseline_train_x.iloc[cycle16_indicies]\n",
    "baseline_train_x = baseline_train_x.append(baseline_train_x.iloc[cycle16_indicies],ignore_index=True)\n",
    "baseline_train_x = baseline_train_x.append(baseline_train_x.iloc[cycle16_indicies],ignore_index=True)\n",
    "baseline_train_x = baseline_train_x.append(baseline_train_x.iloc[cycle16_indicies],ignore_index=True)\n",
    "\n",
    "baseline_train_y = baseline_train_y.append(baseline_train_y.iloc[cycle16_indicies],ignore_index=True)\n",
    "baseline_train_y = baseline_train_y.append(baseline_train_y.iloc[cycle16_indicies],ignore_index=True)\n",
    "baseline_train_y = baseline_train_y.append(baseline_train_y.iloc[cycle16_indicies],ignore_index=True)\n",
    "\n",
    "print(baseline_train_x.shape)\n",
    "xgb_duplicate = XGBClassifier(num_classes = 3, random_state = 12)\n",
    "# preds are gpa, lsat, urm, work_experience, \n",
    "xgb_duplicate.fit(baseline_train_x, baseline_train_y)\n",
    "\n",
    "f1_score_duplicate = f1_score(baseline_test_y, xgb_duplicate.predict(baseline_test_x), average = 'micro')\n",
    "log_loss_duplicate = log_loss(baseline_test_y, xgb_duplicate.predict_proba(baseline_test_x))\n",
    "\n",
    "f1_score_list.append(f1_score_duplicate)\n",
    "log_loss_list.append(log_loss_duplicate)\n",
    "\n",
    "print(f1_score_duplicate)\n",
    "print(log_loss_duplicate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6065573770491803\n",
      "1.041658621479864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushilsheth/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:253: UserWarning:\n",
      "\n",
      "After over-sampling, the number of samples (604) in class 16 will be larger than the number of samples in the majority class (class #15 -> 407)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cycle17_test = school_orig.loc[school_orig.cycleid == 17] # DONT TOUCH\n",
    "cycle17_train = school_orig.loc[school_orig.cycleid != 17]\n",
    "\n",
    "smote_cycle_y = cycle17_train['cycleid']#.to_numpy()\n",
    "smote_cycle_x = cycle17_train.drop('cycleid', axis = 1)#.to_numpy()\n",
    "\n",
    "samp_dict = {}\n",
    "\n",
    "for cycle_id_smote in np.unique(smote_cycle_y):\n",
    "    samp_dict[cycle_id_smote] = smote_cycle_y[smote_cycle_y==cycle_id_smote].shape[0]\n",
    "\n",
    "samp_dict[np.max(smote_cycle_y)] = samp_dict[np.max(smote_cycle_y)]*2\n",
    "oversample = SMOTE(sampling_strategy = samp_dict)\n",
    "\n",
    "\n",
    "X_up, y_up = oversample.fit_resample(smote_cycle_x,smote_cycle_y)\n",
    "\n",
    "df_resample_train = pd.DataFrame(X_up,columns = smote_cycle_x.columns)\n",
    "\n",
    "vandy_2018_cycle_train = df_resample_train #vandy_2018_cycle_train.append([df_cycle16]*3,ignore_index=True)\n",
    "# #SMOTE INSTEAD\n",
    "\n",
    "\n",
    "school_y = vandy_2018_cycle_train['decision_numeric'].to_numpy()\n",
    "school_X = vandy_2018_cycle_train.drop(['decision_numeric'], axis = 1).to_numpy()\n",
    "\n",
    "\n",
    "test_y = cycle17_test['decision_numeric'].to_numpy()\n",
    "test_x = cycle17_test.drop(['decision_numeric', 'cycleid'], axis = 1).to_numpy()\n",
    "\n",
    "\n",
    "xgb_smote = XGBClassifier(num_classes = 3, random_state = 12)\n",
    "# # preds are gpa, lsat, urm, work_experience, \n",
    "xgb_smote.fit(school_X, np.round(school_y+.49))\n",
    "\n",
    "f1_score_smote = f1_score(test_y, xgb_smote.predict(test_x), average = 'micro')\n",
    "log_loss_smote = log_loss(test_y, xgb_smote.predict_proba(test_x))\n",
    "\n",
    "f1_score_list.append(f1_score_smote)\n",
    "log_loss_list.append(log_loss_smote)\n",
    "\n",
    "print(f1_score_smote)\n",
    "print(log_loss_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rushilsheth/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py:253: UserWarning:\n",
      "\n",
      "After over-sampling, the number of samples (604) in class 16 will be larger than the number of samples in the majority class (class #15 -> 407)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6229508196721312\n",
      "1.045362403914027\n"
     ]
    }
   ],
   "source": [
    "# smotenc on cycle\n",
    "\n",
    "cycle17_test_smotenc = school_orig.loc[school_orig.cycleid == 17] # DONT TOUCH\n",
    "cycle17_train_smotenc = school_orig.loc[school_orig.cycleid != 17]\n",
    "\n",
    "samp_dict = {}\n",
    "\n",
    "for cycle_id_smote in np.unique(smote_cycle_y):\n",
    "    samp_dict[cycle_id_smote] = smote_cycle_y[smote_cycle_y==cycle_id_smote].shape[0]\n",
    "samp_dict[np.max(smote_cycle_y)] = samp_dict[np.max(smote_cycle_y)]*2\n",
    "oversample = SMOTENC(sampling_strategy = samp_dict, categorical_features = [0,3,4])\n",
    "\n",
    "smotenc_cycle_y = cycle17_train_smotenc.cycleid\n",
    "smotenc_cycle_x = cycle17_train_smotenc.drop('cycleid', axis = 1)\n",
    "\n",
    "\n",
    "X_up, y_up = oversample.fit_resample(smotenc_cycle_x,smotenc_cycle_y)\n",
    "\n",
    "df_resample_train = pd.DataFrame(X_up,columns = smotenc_cycle_x.columns)\n",
    "\n",
    "smote_2_y = df_resample_train['decision_numeric'].to_numpy()\n",
    "smote_2_X = df_resample_train.drop('decision_numeric', axis =1).to_numpy()\n",
    "\n",
    "# # FIT\n",
    "xgb_smotenc = XGBClassifier(num_classes = 3, random_state = 12)\n",
    "# # # preds are gpa, lsat, urm, work_experience, \n",
    "xgb_smotenc.fit(smote_2_X, smote_2_y)\n",
    "\n",
    "test_y = cycle17_test['decision_numeric'].to_numpy()\n",
    "test_x = cycle17_test.drop(['decision_numeric', 'cycleid'], axis = 1).to_numpy()\n",
    "\n",
    "f1_score_smotenc = f1_score(test_y, xgb_smotenc.predict(test_x), average = 'micro')\n",
    "log_loss_smotenc = log_loss(test_y, xgb_smotenc.predict_proba(test_x))\n",
    "\n",
    "f1_score_list.append(f1_score_smotenc)\n",
    "log_loss_list.append(log_loss_smotenc)\n",
    "\n",
    "print(f1_score_smotenc)\n",
    "print(log_loss_smotenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639344262295082\n",
      "0.9800577321830282\n"
     ]
    }
   ],
   "source": [
    "#smotenc on whole thing\n",
    "smote_2_y = df_resample_train[['decision_numeric']]\n",
    "\n",
    "samp_dict_2 = {}\n",
    "for cycle_id_smote in np.unique(smote_2_y):\n",
    "    samp_dict_2[cycle_id_smote] = np.max(smote_2_y['decision_numeric'].value_counts())\n",
    "oversample_2 = SMOTENC(sampling_strategy = samp_dict_2, categorical_features = [2,3])\n",
    "\n",
    "\n",
    "smote_2_y = smote_2_y.decision_numeric\n",
    "\n",
    "X_fin, y_fin = oversample_2.fit_resample(smote_2_X,smote_2_y)\n",
    "\n",
    "xgb_school = XGBClassifier(num_classes = 3, random_state = 12)\n",
    "# preds are gpa, lsat, urm, work_experience, \n",
    "xgb_school.fit(X_fin, y_fin)\n",
    "\n",
    "f1_score_final = f1_score(test_y, xgb_school.predict(test_x), average = 'micro')\n",
    "log_loss_final = log_loss(test_y, xgb_school.predict_proba(test_x))\n",
    "\n",
    "f1_score_list.append(f1_score_final)\n",
    "log_loss_list.append(log_loss_final)\n",
    "\n",
    "print(f1_score_final)\n",
    "print(log_loss_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6229508196721312,\n",
       " 0.639344262295082,\n",
       " 0.6065573770491803,\n",
       " 0.6229508196721312,\n",
       " 0.639344262295082]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f1_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0031850252025685,\n",
       " 1.0319778619669988,\n",
       " 1.041658621479864,\n",
       " 1.045362403914027,\n",
       " 0.9800577321830282]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels = ['Baseline', 'Duplicate', 'SMOTE', 'SMOTENC', 'SMOTENC twice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>log loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>1.003185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duplicate</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>1.031978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>1.041659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTENC</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>1.045362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTENC twice</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.980058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label  f1 score  log loss\n",
       "0       Baseline  0.622951  1.003185\n",
       "1      Duplicate  0.639344  1.031978\n",
       "2          SMOTE  0.606557  1.041659\n",
       "3        SMOTENC  0.622951  1.045362\n",
       "4  SMOTENC twice  0.639344  0.980058"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_df = df1 = pd.DataFrame(zip(x_labels, f1_score_list, log_loss_list), columns=[\"label\", \"f1 score\", \"log loss\"])\n",
    "fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>score type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>f1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duplicate</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>f1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>f1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTENC</td>\n",
       "      <td>0.622951</td>\n",
       "      <td>f1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMOTENC twice</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>f1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>1.003185</td>\n",
       "      <td>log loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Duplicate</td>\n",
       "      <td>1.031978</td>\n",
       "      <td>log loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>1.041659</td>\n",
       "      <td>log loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SMOTENC</td>\n",
       "      <td>1.045362</td>\n",
       "      <td>log loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SMOTENC twice</td>\n",
       "      <td>0.980058</td>\n",
       "      <td>log loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label     score score type\n",
       "0       Baseline  0.622951   f1 score\n",
       "1      Duplicate  0.639344   f1 score\n",
       "2          SMOTE  0.606557   f1 score\n",
       "3        SMOTENC  0.622951   f1 score\n",
       "4  SMOTENC twice  0.639344   f1 score\n",
       "5       Baseline  1.003185   log loss\n",
       "6      Duplicate  1.031978   log loss\n",
       "7          SMOTE  1.041659   log loss\n",
       "8        SMOTENC  1.045362   log loss\n",
       "9  SMOTENC twice  0.980058   log loss"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_type_f1 = ['f1 score', 'f1 score', 'f1 score', 'f1 score', 'f1 score']\n",
    "score_type_log = ['log loss', 'log loss', 'log loss', 'log loss', 'log loss']\n",
    "\n",
    "df1 = pd.DataFrame(zip(x_labels, f1_score_list, score_type_f1), columns=[\"label\", \"score\", \"score type\"])\n",
    "df2 = pd.DataFrame(zip(x_labels, log_loss_list, score_type_log), columns=[\"label\", \"score\", \"score type\"])\n",
    "\n",
    "df = pd.concat([df1,df2],ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.barplot(x=\"label\", hue=\"score type\", y=\"score\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
